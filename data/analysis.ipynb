{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13de0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liyouhua\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_single_dataset(dataset_name):\n",
    "    \"\"\"åˆ†æå•ä¸ªæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "    file_path = Path(f\"{dataset_name}.jsonl\")\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        question_lengths = []\n",
    "        problem_count = 0\n",
    "        \n",
    "        # è¯»å–JSONLæ–‡ä»¶\n",
    "        with jsonlines.open(file_path, 'r') as reader:\n",
    "            for line in reader:\n",
    "                if 'question' in line:\n",
    "                    question_length = len(line['question'])\n",
    "                    question_lengths.append(question_length)\n",
    "                    problem_count += 1\n",
    "        \n",
    "        if question_lengths:\n",
    "            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡\n",
    "            avg_length = sum(question_lengths) / len(question_lengths)\n",
    "            min_length = min(question_lengths)\n",
    "            max_length = max(question_lengths)\n",
    "            file_size_kb = file_path.stat().st_size / 1024\n",
    "            \n",
    "            stats = {\n",
    "                'dataset': dataset_name,\n",
    "                'problem_count': problem_count,\n",
    "                'avg_length': avg_length,\n",
    "                'min_length': min_length,\n",
    "                'max_length': max_length,\n",
    "                'file_size_kb': file_size_kb\n",
    "            }\n",
    "            \n",
    "            # æ‰“å°ç»“æœ\n",
    "            print(f\"ğŸ“Š æ•°æ®é›†: {dataset_name}\")\n",
    "            print(f\"   é—®é¢˜æ€»æ•°: {problem_count:,} ä¸ª\")\n",
    "            print(f\"   å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦\")\n",
    "            print(f\"   é•¿åº¦èŒƒå›´: {min_length} - {max_length} å­—ç¬¦\")\n",
    "            print(f\"   æ–‡ä»¶å¤§å°: {file_size_kb:.1f} KB\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            return stats\n",
    "        else:\n",
    "            print(f\"âš ï¸  {dataset_name}: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„questionå­—æ®µ\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¤„ç† {dataset_name} æ—¶å‡ºé”™: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# åˆå§‹åŒ–ç»“æœåˆ—è¡¨\n",
    "all_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c655c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ complexor æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: complexor\n",
      "   é—®é¢˜æ€»æ•°: 18 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 809.8 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 504 - 1315 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 15.3 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ complexor æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"complexor\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5b53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ industryor æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: industryor\n",
      "   é—®é¢˜æ€»æ•°: 100 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 1002.0 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 349 - 3556 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 104.0 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ industryor æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"industryor\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffd6097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ mamo_easy æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: mamo_easy\n",
      "   é—®é¢˜æ€»æ•°: 652 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 1045.5 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 528 - 1974 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 702.3 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ mamo_easy æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"mamo_easy\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d1c161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ mamo_complex æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: mamo_complex\n",
      "   é—®é¢˜æ€»æ•°: 211 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 1724.1 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 444 - 3732 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 369.5 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ mamo_complex æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"mamo_complex\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835ceaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ nl4opt æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: nl4opt\n",
      "   é—®é¢˜æ€»æ•°: 231 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 537.5 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 328 - 818 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 132.9 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ nl4opt æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"nl4opt\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b970653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ nlp4lp æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: nlp4lp\n",
      "   é—®é¢˜æ€»æ•°: 242 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 536.6 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 328 - 818 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 139.1 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ nlp4lp æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"nlp4lp\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61530e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æä¿®æ­£åçš„æ•°æ®é›†\n",
      "================================================================================\n",
      "\n",
      "ğŸ” åˆ†æ mamo_easy_re æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: mamo_easy_re\n",
      "   é—®é¢˜æ€»æ•°: 652 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 1128.6 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 581 - 1974 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 759.6 KB\n",
      "==================================================\n",
      "\n",
      "ğŸ” åˆ†æ mamo_complex_re æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: mamo_complex_re\n",
      "   é—®é¢˜æ€»æ•°: 211 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 1832.3 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 469 - 3850 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 393.1 KB\n",
      "==================================================\n",
      "\n",
      "ğŸ” åˆ†æ nlp4lp_re æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: nlp4lp_re\n",
      "   é—®é¢˜æ€»æ•°: 242 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 624.7 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 328 - 922 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 161.3 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æä¿®æ­£åçš„æ•°æ®é›†\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# åˆ†æä¿®æ­£åçš„æ•°æ®é›†\n",
    "print(\"\\nğŸ” åˆ†æ mamo_easy_re æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"mamo_easy_re\")\n",
    "if stats:\n",
    "    all_stats.append(stats)\n",
    "\n",
    "print(\"\\nğŸ” åˆ†æ mamo_complex_re æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"mamo_complex_re\")\n",
    "if stats:\n",
    "    all_stats.append(stats)\n",
    "\n",
    "print(\"\\nğŸ” åˆ†æ nlp4lp_re æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"nlp4lp_re\")\n",
    "if stats:\n",
    "    all_stats.append(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af7938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š æ•°æ®é›†å¯¹æ¯”åˆ†æ\n",
      "================================================================================\n",
      "\n",
      "æ•°æ®é›†ä¿®æ­£å‰åå¯¹æ¯”:\n",
      "----------------------------------------\n",
      "\n",
      "mamo_easy vs mamo_easy_re:\n",
      "  é—®é¢˜æ•°é‡: 652 â†’ 652 (å˜åŒ–: +0)\n",
      "  å¹³å‡é•¿åº¦: 1045.5 â†’ 1128.6 (å˜åŒ–: +83.1)\n",
      "\n",
      "mamo_complex vs mamo_complex_re:\n",
      "  é—®é¢˜æ•°é‡: 211 â†’ 211 (å˜åŒ–: +0)\n",
      "  å¹³å‡é•¿åº¦: 1724.1 â†’ 1832.3 (å˜åŒ–: +108.1)\n",
      "\n",
      "nlp4lp vs nlp4lp_re:\n",
      "  é—®é¢˜æ•°é‡: 242 â†’ 242 (å˜åŒ–: +0)\n",
      "  å¹³å‡é•¿åº¦: 536.6 â†’ 624.7 (å˜åŒ–: +88.1)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# æ¯”è¾ƒåŸå§‹æ•°æ®é›†å’Œä¿®æ­£åæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"ğŸ“Š æ•°æ®é›†å¯¹æ¯”åˆ†æ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all_stats:\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    \n",
    "    # æ‰¾å‡ºéœ€è¦æ¯”è¾ƒçš„æ•°æ®é›†å¯¹\n",
    "    original_datasets = ['mamo_easy', 'mamo_complex', 'nlp4lp']\n",
    "    revised_datasets = ['mamo_easy_re', 'mamo_complex_re', 'nlp4lp_re']\n",
    "    \n",
    "    comparison_data = []\n",
    "    for orig, rev in zip(original_datasets, revised_datasets):\n",
    "        orig_stats = df[df['dataset'] == orig].iloc[0] if not df[df['dataset'] == orig].empty else None\n",
    "        rev_stats = df[df['dataset'] == rev].iloc[0] if not df[df['dataset'] == rev].empty else None\n",
    "        \n",
    "        if orig_stats is not None and rev_stats is not None:\n",
    "            comparison = {\n",
    "                'dataset_pair': f\"{orig} vs {rev}\",\n",
    "                'orig_problems': orig_stats['problem_count'],\n",
    "                'rev_problems': rev_stats['problem_count'],\n",
    "                'orig_avg_len': orig_stats['avg_length'],\n",
    "                'rev_avg_len': rev_stats['avg_length'],\n",
    "                'problem_change': rev_stats['problem_count'] - orig_stats['problem_count'],\n",
    "                'length_change': rev_stats['avg_length'] - orig_stats['avg_length']\n",
    "            }\n",
    "            comparison_data.append(comparison)\n",
    "    \n",
    "    if comparison_data:\n",
    "        comp_df = pd.DataFrame(comparison_data)\n",
    "        print(\"\\næ•°æ®é›†ä¿®æ­£å‰åå¯¹æ¯”:\")\n",
    "        print(\"-\" * 40)\n",
    "        for _, row in comp_df.iterrows():\n",
    "            print(f\"\\n{row['dataset_pair']}:\")\n",
    "            print(f\"  é—®é¢˜æ•°é‡: {row['orig_problems']} â†’ {row['rev_problems']} (å˜åŒ–: {row['problem_change']:+d})\")\n",
    "            print(f\"  å¹³å‡é•¿åº¦: {row['orig_avg_len']:.1f} â†’ {row['rev_avg_len']:.1f} (å˜åŒ–: {row['length_change']:+.1f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c251425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ æ‰€æœ‰æ•°æ®é›†æ±‡æ€»ç»Ÿè®¡\n",
      "================================================================================\n",
      "            æ•°æ®é›†  é—®é¢˜æ•°   å¹³å‡é•¿åº¦  æœ€çŸ­é•¿åº¦  æœ€é•¿é•¿åº¦  æ–‡ä»¶å¤§å°(KB)\n",
      "      complexor   18  809.8   504  1315      15.3\n",
      "     industryor  100 1002.0   349  3556     104.0\n",
      "      mamo_easy  652 1045.5   528  1974     702.3\n",
      "   mamo_complex  211 1724.1   444  3732     369.5\n",
      "         nl4opt  231  537.5   328   818     132.9\n",
      "         nlp4lp  242  536.6   328   818     139.1\n",
      "   mamo_easy_re  652 1128.6   581  1974     759.6\n",
      "mamo_complex_re  211 1832.3   469  3850     393.1\n",
      "      nlp4lp_re  242  624.7   328   922     161.3\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š æ€»ä½“ç»Ÿè®¡:\n",
      "   æ€»é—®é¢˜æ•°: 2,559 ä¸ª\n",
      "   åŠ æƒå¹³å‡é•¿åº¦: 1050.3 å­—ç¬¦\n",
      "   æœ€çŸ­é—®é¢˜: 328 å­—ç¬¦\n",
      "   æœ€é•¿é—®é¢˜: 3850 å­—ç¬¦\n",
      "================================================================================\n",
      "ğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ° dataset_statistics.json\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“ˆ æ‰€æœ‰æ•°æ®é›†æ±‡æ€»ç»Ÿè®¡\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all_stats:\n",
    "    # åˆ›å»ºDataFrameè¿›è¡Œæ›´å¥½çš„å±•ç¤º\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    \n",
    "    # è®¾ç½®æ˜¾ç¤ºæ ¼å¼\n",
    "    pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "    \n",
    "    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº\n",
    "    df = df[['dataset', 'problem_count', 'avg_length', 'min_length', 'max_length', 'file_size_kb']]\n",
    "    \n",
    "    # é‡å‘½ååˆ—\n",
    "    df.columns = ['æ•°æ®é›†', 'é—®é¢˜æ•°', 'å¹³å‡é•¿åº¦', 'æœ€çŸ­é•¿åº¦', 'æœ€é•¿é•¿åº¦', 'æ–‡ä»¶å¤§å°(KB)']\n",
    "    \n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # è®¡ç®—æ€»ä½“ç»Ÿè®¡\n",
    "    total_problems = df['é—®é¢˜æ•°'].sum()\n",
    "    weighted_avg = (df['å¹³å‡é•¿åº¦'] * df['é—®é¢˜æ•°']).sum() / total_problems\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ğŸ“Š æ€»ä½“ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»é—®é¢˜æ•°: {total_problems:,} ä¸ª\")\n",
    "    print(f\"   åŠ æƒå¹³å‡é•¿åº¦: {weighted_avg:.1f} å­—ç¬¦\")\n",
    "    print(f\"   æœ€çŸ­é—®é¢˜: {df['æœ€çŸ­é•¿åº¦'].min()} å­—ç¬¦\")\n",
    "    print(f\"   æœ€é•¿é—®é¢˜: {df['æœ€é•¿é•¿åº¦'].max()} å­—ç¬¦\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    results_dict = {\n",
    "        'individual_stats': all_stats,\n",
    "        'summary': {\n",
    "            'total_problems': int(total_problems),\n",
    "            'weighted_average_length': float(weighted_avg),\n",
    "            'global_min_length': int(df['æœ€çŸ­é•¿åº¦'].min()),\n",
    "            'global_max_length': int(df['æœ€é•¿é•¿åº¦'].max())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # with open('dataset_statistics.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(results_dict, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"ğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ° dataset_statistics.json\")\n",
    "else:\n",
    "    print(\"âŒ æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•æ•°æ®é›†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "221869ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ ICML æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: ICML\n",
      "   é—®é¢˜æ€»æ•°: 410 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 649.3 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 309 - 2186 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 280.7 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ ICML æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"ICML\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0f25afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ optibench æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: optibench\n",
      "   é—®é¢˜æ€»æ•°: 605 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 686.5 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 64 - 2186 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 436.6 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ optibench æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"optibench\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccab46f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” åˆ†æ optmath æ•°æ®é›†\n",
      "ğŸ“Š æ•°æ®é›†: optmath\n",
      "   é—®é¢˜æ€»æ•°: 166 ä¸ª\n",
      "   å¹³å‡é•¿åº¦: 2891.0 å­—ç¬¦\n",
      "   é•¿åº¦èŒƒå›´: 1116 - 7890 å­—ç¬¦\n",
      "   æ–‡ä»¶å¤§å°: 481.8 KB\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” åˆ†æ optmath æ•°æ®é›†\")\n",
    "stats = analyze_single_dataset(\"optmath\")\n",
    "if stats:\n",
    "    all_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d9c15e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ˆ æ‰€æœ‰æ•°æ®é›†æ±‡æ€»ç»Ÿè®¡\n",
      "================================================================================\n",
      "            æ•°æ®é›†  é—®é¢˜æ•°   å¹³å‡é•¿åº¦  æœ€çŸ­é•¿åº¦  æœ€é•¿é•¿åº¦  æ–‡ä»¶å¤§å°(KB)\n",
      "      complexor   18  809.8   504  1315      15.3\n",
      "     industryor  100 1002.0   349  3556     104.0\n",
      "      mamo_easy  652 1045.5   528  1974     702.3\n",
      "   mamo_complex  211 1724.1   444  3732     369.5\n",
      "         nl4opt  231  537.5   328   818     132.9\n",
      "         nlp4lp  242  536.6   328   818     139.1\n",
      "   mamo_easy_re  652 1128.6   581  1974     759.6\n",
      "mamo_complex_re  211 1832.3   469  3850     393.1\n",
      "      nlp4lp_re  242  624.7   328   922     161.3\n",
      "           ICML  410  649.3   309  2186     280.7\n",
      "      optibench  605  686.5    64  2186     436.6\n",
      "        optmath  166 2891.0  1116  7890     481.8\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š æ€»ä½“ç»Ÿè®¡:\n",
      "   æ€»é—®é¢˜æ•°: 3,740 ä¸ª\n",
      "   åŠ æƒå¹³å‡é•¿åº¦: 1029.2 å­—ç¬¦\n",
      "   æœ€çŸ­é—®é¢˜: 64 å­—ç¬¦\n",
      "   æœ€é•¿é—®é¢˜: 7890 å­—ç¬¦\n",
      "================================================================================\n",
      "ğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ° dataset_statistics.json\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“ˆ æ‰€æœ‰æ•°æ®é›†æ±‡æ€»ç»Ÿè®¡\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all_stats:\n",
    "    # åˆ›å»ºDataFrameè¿›è¡Œæ›´å¥½çš„å±•ç¤º\n",
    "    df = pd.DataFrame(all_stats)\n",
    "    \n",
    "    # è®¾ç½®æ˜¾ç¤ºæ ¼å¼\n",
    "    pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "    \n",
    "    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº\n",
    "    df = df[['dataset', 'problem_count', 'avg_length', 'min_length', 'max_length', 'file_size_kb']]\n",
    "    \n",
    "    # é‡å‘½ååˆ—\n",
    "    df.columns = ['æ•°æ®é›†', 'é—®é¢˜æ•°', 'å¹³å‡é•¿åº¦', 'æœ€çŸ­é•¿åº¦', 'æœ€é•¿é•¿åº¦', 'æ–‡ä»¶å¤§å°(KB)']\n",
    "    \n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # è®¡ç®—æ€»ä½“ç»Ÿè®¡\n",
    "    total_problems = df['é—®é¢˜æ•°'].sum()\n",
    "    weighted_avg = (df['å¹³å‡é•¿åº¦'] * df['é—®é¢˜æ•°']).sum() / total_problems\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"ğŸ“Š æ€»ä½“ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»é—®é¢˜æ•°: {total_problems:,} ä¸ª\")\n",
    "    print(f\"   åŠ æƒå¹³å‡é•¿åº¦: {weighted_avg:.1f} å­—ç¬¦\")\n",
    "    print(f\"   æœ€çŸ­é—®é¢˜: {df['æœ€çŸ­é•¿åº¦'].min()} å­—ç¬¦\")\n",
    "    print(f\"   æœ€é•¿é—®é¢˜: {df['æœ€é•¿é•¿åº¦'].max()} å­—ç¬¦\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ä¿å­˜ç»“æœ\n",
    "    results_dict = {\n",
    "        'individual_stats': all_stats,\n",
    "        'summary': {\n",
    "            'total_problems': int(total_problems),\n",
    "            'weighted_average_length': float(weighted_avg),\n",
    "            'global_min_length': int(df['æœ€çŸ­é•¿åº¦'].min()),\n",
    "            'global_max_length': int(df['æœ€é•¿é•¿åº¦'].max())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # with open('dataset_statistics.json', 'w', encoding='utf-8') as f:\n",
    "    #     json.dump(results_dict, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"ğŸ’¾ ç»Ÿè®¡ç»“æœå·²ä¿å­˜åˆ° dataset_statistics.json\")\n",
    "else:\n",
    "    print(\"âŒ æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•æ•°æ®é›†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a543bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
